<!DOCTYPE html>
<html><head><meta charset="utf-8"><script src="main.js" type="text/javascript"></script><script type="text/javascript">tailrecursion.hoplon.app_pages._example_deck_DOT_html.hoploninit();</script><link rel="stylesheet" href="custom.css"></head><body><div class="reveal"><link rel="stylesheet" href="reveal.js/css/reveal.css"><link id="theme" rel="stylesheet" href="reveal.js/css/theme/simple.css"><link rel="stylesheet" href="reveal.js/plugin/highlight/github.min.css"><div class="slides"><section><h1 class="slide-title intro">Factorization Techniques for Recommendation</h1><div>Paul English</div><div><a shape="rect" href="mailto:paul.english@utah.edu">paul.english@utah.edu</a></div><div><a shape="rect" href="https://github.com/log0ymxm">https://github.com/log0ymxm</a></div></section><section><section><h2 class="slide-title chapter">What is Recommendation?</h2></section><section><h3 class="slide-title slide">Some Obvious Examples</h3><ul><li>Netflix suggesting movies you might like after you've added some ratings</li><li>Amazon offering "commonly sold together" discount packages</li><li>Facebook showing "friends you might know"</li></ul></section><section><h3 class="slide-title slide">We can think of recommendation problems as a graph or network</h3><div>Multiple vertices with edges connecting them.</div><img src="img/graphs/Alemdar@Alemdar.gif" width="260" height="260"><img src="img/graphs/Grund@poli_large.APlusAT.gif" width="260" height="260"><img src="img/graphs/QCD@conf5_0-4x4-10.gif" width="260" height="260"></section><section><h3 class="slide-title slide">They are seen in all kinds of industries</h3><ul><li>Social Networks</li><li>Communication Networks</li><li>Road Networks</li><li>Product Networks</li><li>...</li></ul></section><section><h3 class="slide-title slide">We can look at different aspects of the data</h3><ul><li>Content Based Filtering</li><li>Collaborative Filtering</li></ul></section><section><h3 class="slide-title slide">There are different ways to solve the collaborative problem</h3><ul><li>Item Similarity / Nearest Neighbors</li><li>Factorization and Latent Dimensions</li></ul></section></section><section><section><h2 class="slide-title chapter">Matrix Factorization</h2></section><section><h3 class="slide-title slide">Matrix Factorization is the process of seperating one matrix into multiple factor matrices</h3><pre>$$R =
[[5.000 3.000 0.000 1.000]
 [4.000 0.000 0.000 1.000]
 [1.000 1.000 0.000 5.000]
 [1.000 0.000 0.000 4.000]
 [0.000 1.000 5.000 4.000]]

s.t.
[[2.204 -0.017]
 [1.475  0.008]
 [0.799  1.414]
 [0.609  1.104]
 [0.006  2.150]]
[[ 2.323 -0.215]
 [ 0.865  0.250]
 [-0.317  1.442]
 [ 0.727  2.391]]
[[ 5.124 1.903 -0.724 1.563]
 [ 3.426 1.279 -0.457 1.091]
 [ 1.551 1.045  1.785 3.961]
 [ 1.178 0.804  1.399 3.083]
 [-0.449 0.543  3.100 5.146]]$$</pre></section><section><h3 class="slide-title slide">You can think of it like pulling apart a matrix</h3><img class="no-border" src="img/matrix-multiplication-split.png"></section><section><h3 class="slide-title slide">This lets us capture the relationships between each item and user</h3><div style="position:relative;width:100%;height:400px;"><img class="fragment no-border current-visible" src="img/factor-relations/factor-relations-step-1.png" style="position:absolute;left:0;top:0;" width="100%"><img class="fragment no-border" src="img/factor-relations/factor-relations-step-2.png" style="position:absolute;left:0;top:0;" width="100%"><img class="fragment no-border" src="img/factor-relations/factor-relations-step-3.png" style="position:absolute;left:0;top:0;" width="100%"><img class="fragment no-border" src="img/factor-relations/factor-relations-step-4.png" style="position:absolute;left:0;top:0;" width="100%"><img class="fragment no-border" src="img/factor-relations/factor-relations-step-5.png" style="position:absolute;left:0;top:0;" width="100%"><img class="fragment no-border" src="img/factor-relations/factor-relations-step-cross.png" style="position:absolute;left:0;top:0;" width="100%"></div></section><section><h3 class="slide-title slide">We find our factor matrices using an optimization routine</h3><div>e.g. gradient descent</div><img class="no-border" src="img/gradient-descent/DisplayVelocityPlotOverContourPlotExample_02.png"></section></section><section><section><h2 class="slide-title chapter">Building on the Matrix Factorization Model</h2></section><section><h3 class="slide-title slide">Including Additional Information</h3></section><section><h3 class="slide-title slide">Making use of time</h3></section><section><h3 class="slide-title slide">Confidence Intervals</h3></section></section><section><section><h2 class="slide-title chapter">The Factorization Machine</h2></section><section><h3 class="slide-title slide">What is this?</h3><img src="img/lego-car-seankenney.jpg"><div class="fragment"><p><strike>car</strike></p><p>legos!</p></div></section><section><h3 class="slide-title slide">The Factorization Machine is a generalization of traditional matrix factorization techniques</h3><div>Matrix factorization is a specialized case of the factorization machine.</div></section><section><h3 class="slide-title slide">It earns it's name from the Support Vector Machine</h3></section><section><h3 class="slide-title slide">But really it's not much like an SVM</h3></section><section><h3 class="slide-title slide">It's a generalized learning technique</h3></section></section><section><section><h2 class="slide-title chapter">Questions?</h2></section><section><h3 class="slide-title slide">Thanks!</h3><div>Paul English</div><div><a shape="rect" href="mailto:paul.english@utah.edu">paul.english@utah.edu</a></div><div><a shape="rect" href="https://github.com/log0ymxm">https://github.com/log0ymxm</a></div></section><section><h3 class="slide-title slide">References</h3></section></section></div></div></body></html>